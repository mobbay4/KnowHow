{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Foreword This is a Repository for knowledge sharing. The Idea is to document solutions for Problems one had to solve.","title":"Foreword"},{"location":"index.html#foreword","text":"This is a Repository for knowledge sharing. The Idea is to document solutions for Problems one had to solve.","title":"Foreword"},{"location":"Programming/Git/git_general.html","text":"General hints on Git In this section, useful git commands and workflows should be collected. Commands Branches Show branches: git branch # to show local branches git branch # to show local and remote branches Create branches: git checkout -b <branch> # creates and switches to <branch> To make it available remotely: git push --set-upstream origin <branch> local: git branch -d <branch> The '-d' option stands for '-delete', and it can be used whenever the branch you want to clean up is completely merged with your upstream branch. git branch -D <branch> In this case, the '-D' option stands for '-delete -force', and it is used when your local branches are not merged with your remote-tracking branches. remote : remote branches git push <remote> --delete <branch> Merge To merge another branch in your active branch: git merge <branch> Not auto-mergeable files have to be resolved manually. To get a merge preview, one can use: git diff <source_branch> <target_branch> log To study the repository history: git log There are several parameters one can adjust: --author = boy --graph --oneline --decorate --all # shows reduced git commit history Undo current chagnes ( Reference ) This discards local changes to all files permanently: Git reset --hard Unstaged but keep changes git reset SSH Agent One can secure his SSH keys and configure an authentication agent so that you will not have to reenter your passphrase every time you use your SSH keys. This tutorial explains how to configure the SSH-Agent . Commit Messages There are several ways to write comprehencive commit messages. This nice block article gives some very introductive tipps what makes a commit message readable. Also it informs one on how to structure it that GitLab can present it correctly.","title":"General Git Hints"},{"location":"Programming/Git/git_general.html#general-hints-on-git","text":"In this section, useful git commands and workflows should be collected.","title":"General hints on Git"},{"location":"Programming/Git/git_general.html#commands","text":"","title":"Commands"},{"location":"Programming/Git/git_general.html#branches","text":"Show branches: git branch # to show local branches git branch # to show local and remote branches Create branches: git checkout -b <branch> # creates and switches to <branch> To make it available remotely: git push --set-upstream origin <branch> local: git branch -d <branch> The '-d' option stands for '-delete', and it can be used whenever the branch you want to clean up is completely merged with your upstream branch. git branch -D <branch> In this case, the '-D' option stands for '-delete -force', and it is used when your local branches are not merged with your remote-tracking branches. remote : remote branches git push <remote> --delete <branch>","title":"Branches"},{"location":"Programming/Git/git_general.html#merge","text":"To merge another branch in your active branch: git merge <branch> Not auto-mergeable files have to be resolved manually. To get a merge preview, one can use: git diff <source_branch> <target_branch>","title":"Merge"},{"location":"Programming/Git/git_general.html#log","text":"To study the repository history: git log There are several parameters one can adjust: --author = boy --graph --oneline --decorate --all # shows reduced git commit history","title":"log"},{"location":"Programming/Git/git_general.html#undo-current-chagnes-reference","text":"This discards local changes to all files permanently: Git reset --hard Unstaged but keep changes git reset","title":"Undo current chagnes (Reference)"},{"location":"Programming/Git/git_general.html#ssh-agent","text":"One can secure his SSH keys and configure an authentication agent so that you will not have to reenter your passphrase every time you use your SSH keys. This tutorial explains how to configure the SSH-Agent .","title":"SSH Agent"},{"location":"Programming/Git/git_general.html#commit-messages","text":"There are several ways to write comprehencive commit messages. This nice block article gives some very introductive tipps what makes a commit message readable. Also it informs one on how to structure it that GitLab can present it correctly.","title":"Commit Messages"},{"location":"Programming/Git/git_hooks.html","text":"Git Hooks Git hooks are tasks (like in the GitLab CI/CD) that are executed before a commit. This is useful to for example test for certain requirements before a commit is fulfilled. This becomes exspeacially handy for linting and testing tasks. Such as using pytest or black . To implement git-hooks one uses the pre-commit Python package to use common hooks in a simple way. But there is also the posibility to implement own git hooks in bash logic. Sadly there is no experience on custom git hooks so far. The following sections explain the general configurations and how to run certain hooks using pre-commit . General configuration To configure pre-commit please follow one of these tutorials: git-hook-tutorial-1 git-hook-tutorial-2 By doing so several observations have been made that may helpful to you. First of all to use the pre-commit command its strongly recomended to install it in an virtual environment since otherwise the command can not be found. After the .pre-commit-config.yaml file is installed once the git hooks apply automatically on every commit in the git repository. Step by step guide So to create a git-hook configuration for an git repository I would do the following steps (in an cmd terminal): create a fresh virtual-environment, activate and install pre-commit with: python -m virtualenv venv venv \\S cripts \\a ctivate pip install pre-commit create a .pre-commit-config.yaml (template in the end of this chapter) and install it to the git-repository with: pre-commit install Now the defined git-hooks should apply on each commit Here you can find an overview of all available hooks . In the next section one can see how to insert the specified hooks. For me it was very usefull to use the following command that allows to apply the git hooks on all repository files: pre-commit run --all-files Example Configuration The next code block shows an example how one can define the .pre-commit-config.yaml file. The corresponding tools are shortly explained in the following subsections. In general pre-commit takes care about the installation and configuration of the tools. So a pip install or similar is not nessesary to use git-hooks. repos : - repo : https://github.com/pre-commit/pre-commit-hooks rev : v4.1.0 hooks : - id : trailing-whitespace - id : end-of-file-fixer - id : check-json - id : check-yaml - repo : https://github.com/pre-commit/pre-commit-hooks rev : v2.5.0 hooks : - id : check-added-large-files - repo : https://github.com/pycqa/isort rev : 5.5.4 hooks : - id : isort files : \"\\\\.(py)$\" args : [ --settings-path=pyproject.toml ] - repo : https://github.com/psf/black rev : 19.10b0 hooks : - id : black - repo : https://github.com/PyCQA/flake8 rev : 4.0.1 hooks : - id : flake8 additional_dependencies : [ flake8-typing-imports==1.12.0 ] - repo : https://github.com/igorshubovych/markdownlint-cli rev : v0.31.1 hooks : - id : markdownlint-fix - repo : https://github.com/editorconfig-checker/editorconfig-checker.python rev : 2.4.0 # pick a git hash / tag to point to hooks : - id : editorconfig-checker alias : ec Markdownlint-cli The Markdownlint-cli hook parses over all .md files and checks if the recomended syntax is used. When the -fix option is used, simple errors like missing spacings are fixed automatically. The .markdownlint.jsonc file is used configure the tool. In there one can exclude certain rules (like line length limitation). We normally also introduce the Markdownlint-cli in the GitLab CI/CD to gain an overview on all .md files. black black is a Python package that autoformates Python code to a certain standard. Thereby no functional changes are made but rather optical like additional spacings and identing. black is very useful since it makes the code very readable. flake8 [flake8] checks the code for the PEP8 standard and gives succetions where the code should be modified. This can reveal weaknesses in the code and can even teach a programmer important details. [flake8] is configured by the .flake8 file. editorconfig-checker The eclint tool reads the .editorconfig file and checks if all files in the repository apply to this standard. For deviations it gives feedback for the developer. eclint is configured by the .ecrc file. isort [isort] sorts the imports of an Python module in alphabetic order. pre-commit-hooks pre-commit-hooks are pre-commit native hooks that excecute mostly very simple tasks. We currently use the following: trailing-whitespace end-of-file-fixer check-json check-yaml check-added-large-files Checks if there are files larger than 5 MB. Since GitLab reposetories are not intended to save large files in them. GitLab storage is very expencive!!","title":"Git Hooks"},{"location":"Programming/Git/git_hooks.html#git-hooks","text":"Git hooks are tasks (like in the GitLab CI/CD) that are executed before a commit. This is useful to for example test for certain requirements before a commit is fulfilled. This becomes exspeacially handy for linting and testing tasks. Such as using pytest or black . To implement git-hooks one uses the pre-commit Python package to use common hooks in a simple way. But there is also the posibility to implement own git hooks in bash logic. Sadly there is no experience on custom git hooks so far. The following sections explain the general configurations and how to run certain hooks using pre-commit .","title":"Git Hooks"},{"location":"Programming/Git/git_hooks.html#general-configuration","text":"To configure pre-commit please follow one of these tutorials: git-hook-tutorial-1 git-hook-tutorial-2 By doing so several observations have been made that may helpful to you. First of all to use the pre-commit command its strongly recomended to install it in an virtual environment since otherwise the command can not be found. After the .pre-commit-config.yaml file is installed once the git hooks apply automatically on every commit in the git repository.","title":"General configuration"},{"location":"Programming/Git/git_hooks.html#step-by-step-guide","text":"So to create a git-hook configuration for an git repository I would do the following steps (in an cmd terminal): create a fresh virtual-environment, activate and install pre-commit with: python -m virtualenv venv venv \\S cripts \\a ctivate pip install pre-commit create a .pre-commit-config.yaml (template in the end of this chapter) and install it to the git-repository with: pre-commit install Now the defined git-hooks should apply on each commit Here you can find an overview of all available hooks . In the next section one can see how to insert the specified hooks. For me it was very usefull to use the following command that allows to apply the git hooks on all repository files: pre-commit run --all-files","title":"Step by step guide"},{"location":"Programming/Git/git_hooks.html#example-configuration","text":"The next code block shows an example how one can define the .pre-commit-config.yaml file. The corresponding tools are shortly explained in the following subsections. In general pre-commit takes care about the installation and configuration of the tools. So a pip install or similar is not nessesary to use git-hooks. repos : - repo : https://github.com/pre-commit/pre-commit-hooks rev : v4.1.0 hooks : - id : trailing-whitespace - id : end-of-file-fixer - id : check-json - id : check-yaml - repo : https://github.com/pre-commit/pre-commit-hooks rev : v2.5.0 hooks : - id : check-added-large-files - repo : https://github.com/pycqa/isort rev : 5.5.4 hooks : - id : isort files : \"\\\\.(py)$\" args : [ --settings-path=pyproject.toml ] - repo : https://github.com/psf/black rev : 19.10b0 hooks : - id : black - repo : https://github.com/PyCQA/flake8 rev : 4.0.1 hooks : - id : flake8 additional_dependencies : [ flake8-typing-imports==1.12.0 ] - repo : https://github.com/igorshubovych/markdownlint-cli rev : v0.31.1 hooks : - id : markdownlint-fix - repo : https://github.com/editorconfig-checker/editorconfig-checker.python rev : 2.4.0 # pick a git hash / tag to point to hooks : - id : editorconfig-checker alias : ec","title":"Example Configuration"},{"location":"Programming/Git/git_hooks.html#markdownlint-cli","text":"The Markdownlint-cli hook parses over all .md files and checks if the recomended syntax is used. When the -fix option is used, simple errors like missing spacings are fixed automatically. The .markdownlint.jsonc file is used configure the tool. In there one can exclude certain rules (like line length limitation). We normally also introduce the Markdownlint-cli in the GitLab CI/CD to gain an overview on all .md files.","title":"Markdownlint-cli"},{"location":"Programming/Git/git_hooks.html#black","text":"black is a Python package that autoformates Python code to a certain standard. Thereby no functional changes are made but rather optical like additional spacings and identing. black is very useful since it makes the code very readable.","title":"black"},{"location":"Programming/Git/git_hooks.html#flake8","text":"[flake8] checks the code for the PEP8 standard and gives succetions where the code should be modified. This can reveal weaknesses in the code and can even teach a programmer important details. [flake8] is configured by the .flake8 file.","title":"flake8"},{"location":"Programming/Git/git_hooks.html#editorconfig-checker","text":"The eclint tool reads the .editorconfig file and checks if all files in the repository apply to this standard. For deviations it gives feedback for the developer. eclint is configured by the .ecrc file.","title":"editorconfig-checker"},{"location":"Programming/Git/git_hooks.html#isort","text":"[isort] sorts the imports of an Python module in alphabetic order.","title":"isort"},{"location":"Programming/Git/git_hooks.html#pre-commit-hooks","text":"pre-commit-hooks are pre-commit native hooks that excecute mostly very simple tasks. We currently use the following: trailing-whitespace end-of-file-fixer check-json check-yaml","title":"pre-commit-hooks"},{"location":"Programming/Git/git_hooks.html#check-added-large-files","text":"Checks if there are files larger than 5 MB. Since GitLab reposetories are not intended to save large files in them. GitLab storage is very expencive!!","title":"check-added-large-files"},{"location":"Programming/Python/poetry.html","text":"Poetry Poetry is a package manager that unifies several tasks like dependency management or building and publishing your package. It enables you to define your dependencies precisely. Consequently, another user can be sure to have the same environment as you. To Conclude Poetry centralizes a large part of package management that before was distributed over several packages and files. In this adorable Poetry tutorial one gets an overview and a first hand on how to use Poetry . pyproject.toml In this file, one defines the dependencies and information for a Python project. It can look like this: # pyproject.toml [tool.poetry] name = \"rp-poetry\" version = \"0.1.0\" description = \"\" authors = [ \"Philipp <philipp@realpython.com>\" ] [tool.poetry.dependencies] python = \"^3.9\" [tool.poetry.dev-dependencies] pytest = \"^5.2\" [build-system] requires = [ \"poetry-core>=1.0.0\" ] build-backend = \"poetry.core.masonry.api\" The advantage over the classical requirements.txt file is that one can define separate dependencies for development and package building.","title":"Poetry"},{"location":"Programming/Python/poetry.html#poetry","text":"Poetry is a package manager that unifies several tasks like dependency management or building and publishing your package. It enables you to define your dependencies precisely. Consequently, another user can be sure to have the same environment as you. To Conclude Poetry centralizes a large part of package management that before was distributed over several packages and files. In this adorable Poetry tutorial one gets an overview and a first hand on how to use Poetry .","title":"Poetry"},{"location":"Programming/Python/poetry.html#pyprojecttoml","text":"In this file, one defines the dependencies and information for a Python project. It can look like this: # pyproject.toml [tool.poetry] name = \"rp-poetry\" version = \"0.1.0\" description = \"\" authors = [ \"Philipp <philipp@realpython.com>\" ] [tool.poetry.dependencies] python = \"^3.9\" [tool.poetry.dev-dependencies] pytest = \"^5.2\" [build-system] requires = [ \"poetry-core>=1.0.0\" ] build-backend = \"poetry.core.masonry.api\" The advantage over the classical requirements.txt file is that one can define separate dependencies for development and package building.","title":"pyproject.toml"},{"location":"Programming/UNIT_Tests/python.html","text":"UNIT tests in Python First of all, there is a folder test in parallel to the source-code folder of the Python package, containing all testing files. In this folder, we add a README.md file explaining how the tests are structured. test-functions AssertEqual-function : compare a return value of a function/class with a expected value If we test only on exceptions: Assert(True) If we want to test on a special exception, we use assertions about expected exceptions `setup function: To prepare for the tests, for example, provide access to a database. The setup function runs at first. TearDown-function : Diminish the test resources after the tests, for example, to cut the connection to a database. Call of tests We call tests via the command line. Thereby we can select which tests should run and also skip tests. Later is helpful if the package is not developed enough to execute a particular test. Test results The results are presented in a JUnitXML -file, which can be opened in a browser window. Thereof we get a graphical response about the test results. How to organize the expected values of the tests Parameterization of test-functions For n test values (e.g., by a limiter), it makes sense to parameterize the test functions. The test cases can be created in the test modules or separate parameter files. Parameterization has the advantage that it is immediately visible which test has failed in case of an error. Usage of test-classes Test classes are mainly for test organization. Therefore one understands, which test functions are connected since they are collected in one class. Test types Limit-tests: Execute value below lower border and above upper border as test sign-test Testing in Python The absolute standard package is the Pytest -package. Pytest contains the following components: there is a test folder there is a test runner Conftest.py configures the tests Pytest fixture (deocrator) : Test preparation and clean up for code Test-files : module names all have the prefix test in their filenames Test-functions : Function-names also have the prefix test . The rest of the name should be as descriptive as possible. tests can be parameterized Test coverage One can use tools like Codecov to measure the test-coverage of your code. It runs through all your source code files and checks which lines are covered by the tests you have written so far. Thereoff you can detect potential weaknesses in your code. To learn more one can have a look at this more general but excelent tutorial","title":"Unit Testing"},{"location":"Programming/UNIT_Tests/python.html#unit-tests-in-python","text":"First of all, there is a folder test in parallel to the source-code folder of the Python package, containing all testing files. In this folder, we add a README.md file explaining how the tests are structured.","title":"UNIT tests in Python"},{"location":"Programming/UNIT_Tests/python.html#test-functions","text":"AssertEqual-function : compare a return value of a function/class with a expected value If we test only on exceptions: Assert(True) If we want to test on a special exception, we use assertions about expected exceptions `setup function: To prepare for the tests, for example, provide access to a database. The setup function runs at first. TearDown-function : Diminish the test resources after the tests, for example, to cut the connection to a database.","title":"test-functions"},{"location":"Programming/UNIT_Tests/python.html#call-of-tests","text":"We call tests via the command line. Thereby we can select which tests should run and also skip tests. Later is helpful if the package is not developed enough to execute a particular test.","title":"Call of tests"},{"location":"Programming/UNIT_Tests/python.html#test-results","text":"The results are presented in a JUnitXML -file, which can be opened in a browser window. Thereof we get a graphical response about the test results.","title":"Test results"},{"location":"Programming/UNIT_Tests/python.html#how-to-organize-the-expected-values-of-the-tests","text":"","title":"How to organize the expected values of the tests"},{"location":"Programming/UNIT_Tests/python.html#parameterization-of-test-functions","text":"For n test values (e.g., by a limiter), it makes sense to parameterize the test functions. The test cases can be created in the test modules or separate parameter files. Parameterization has the advantage that it is immediately visible which test has failed in case of an error.","title":"Parameterization of test-functions"},{"location":"Programming/UNIT_Tests/python.html#usage-of-test-classes","text":"Test classes are mainly for test organization. Therefore one understands, which test functions are connected since they are collected in one class.","title":"Usage of test-classes"},{"location":"Programming/UNIT_Tests/python.html#test-types","text":"Limit-tests: Execute value below lower border and above upper border as test sign-test","title":"Test types"},{"location":"Programming/UNIT_Tests/python.html#testing-in-python","text":"The absolute standard package is the Pytest -package. Pytest contains the following components: there is a test folder there is a test runner Conftest.py configures the tests Pytest fixture (deocrator) : Test preparation and clean up for code Test-files : module names all have the prefix test in their filenames Test-functions : Function-names also have the prefix test . The rest of the name should be as descriptive as possible. tests can be parameterized","title":"Testing in Python"},{"location":"Programming/UNIT_Tests/python.html#test-coverage","text":"One can use tools like Codecov to measure the test-coverage of your code. It runs through all your source code files and checks which lines are covered by the tests you have written so far. Thereoff you can detect potential weaknesses in your code. To learn more one can have a look at this more general but excelent tutorial","title":"Test coverage"},{"location":"annex/getting_started.html","text":"Getting Started The following explains how to set up the local environment to write and deploy the documentation. Environment Setup First of all, we need to clone the repository structure locally. For the moment, it is intended to have the following local folder structure : Know_How \u2514\u2500\u2500\u2500 master # folder containing clone of master branch \u2514\u2500\u2500\u2500 gh-pages # folder containing clone of gh-pages branch We want folders for the two branches since if we want to deploy our documentation on GitLab, we need to build it locally and push it to the gh-pages branch. The documentation deployment is explained in the next section. So to introduce this local environment, we perform following steps : create a folder Know_How in the latter folder, clone the repository twice and rename cloned folders to master and gh-pages then move into the gh-pages folder execute the command $ git checkout gh-pages for switching to the right branch Now we move to the master folder execute pip install virtualenv create an virtual environment with $ virtualenv venv (may $ python -m virtualenv venv ) activate the environment with $ source venv/bin/activate install the requirements with $ pip install -r requirements.txt configure the git hooks with $ pre-commit install Now the basic setup is done. The git-hooks are executed before every commit in the master branch. So it is recommended to commit before deploying the documentation. One can apply the git-hooks on all repository files with: $ pre-commit run --all-files Deploy the Documentation We need to build and push the static HTML to the gh-pages branch to deploy the documentation. With the above described set up this process is (at least a bit simplified) by the deploy.sh script. Move to the gh-pages folder and execute bash deploy.sh . This automatically builds, moves, and pushes the documentation to the correct branch. Add Content to the Documentation The add content, one has to modify the files in the /docs folder in the master branch. Just add to existing files or create new ones and add your content. To add new files, one must also adjust the nav section in the mkdocs.yml file.","title":"Getting Started"},{"location":"annex/getting_started.html#getting-started","text":"The following explains how to set up the local environment to write and deploy the documentation.","title":"Getting Started"},{"location":"annex/getting_started.html#environment-setup","text":"First of all, we need to clone the repository structure locally. For the moment, it is intended to have the following local folder structure : Know_How \u2514\u2500\u2500\u2500 master # folder containing clone of master branch \u2514\u2500\u2500\u2500 gh-pages # folder containing clone of gh-pages branch We want folders for the two branches since if we want to deploy our documentation on GitLab, we need to build it locally and push it to the gh-pages branch. The documentation deployment is explained in the next section. So to introduce this local environment, we perform following steps : create a folder Know_How in the latter folder, clone the repository twice and rename cloned folders to master and gh-pages then move into the gh-pages folder execute the command $ git checkout gh-pages for switching to the right branch Now we move to the master folder execute pip install virtualenv create an virtual environment with $ virtualenv venv (may $ python -m virtualenv venv ) activate the environment with $ source venv/bin/activate install the requirements with $ pip install -r requirements.txt configure the git hooks with $ pre-commit install Now the basic setup is done. The git-hooks are executed before every commit in the master branch. So it is recommended to commit before deploying the documentation. One can apply the git-hooks on all repository files with: $ pre-commit run --all-files","title":"Environment Setup"},{"location":"annex/getting_started.html#deploy-the-documentation","text":"We need to build and push the static HTML to the gh-pages branch to deploy the documentation. With the above described set up this process is (at least a bit simplified) by the deploy.sh script. Move to the gh-pages folder and execute bash deploy.sh . This automatically builds, moves, and pushes the documentation to the correct branch.","title":"Deploy the Documentation"},{"location":"annex/getting_started.html#add-content-to-the-documentation","text":"The add content, one has to modify the files in the /docs folder in the master branch. Just add to existing files or create new ones and add your content. To add new files, one must also adjust the nav section in the mkdocs.yml file.","title":"Add Content to the Documentation"},{"location":"annex/how_to_contribute.html","text":"How to Contribute This section explains how to contribute shit to this knowledge collection. First, you should set up a local environment as explained in the getting started . After this, you can add any tutorials, link collections, or explanations you find helpful. :)","title":"How to Contribute"},{"location":"annex/how_to_contribute.html#how-to-contribute","text":"This section explains how to contribute shit to this knowledge collection. First, you should set up a local environment as explained in the getting started . After this, you can add any tutorials, link collections, or explanations you find helpful. :)","title":"How to Contribute"}]}